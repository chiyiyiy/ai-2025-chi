QA1.當我們揮手控制 DronePaint 中的無人機時，哪些資訊是被電腦「看見」並轉化成動作的？請用自己的話解釋手勢辨識背後的機制流程

當我們用手勢來控制 DronePaint 中的無人機時，整個過程就像是電腦在「看」我們的手在做什麼，然後做出相對應的反應。

首先，鏡頭會即時拍下我們的動作，電腦會從影像中找出手部的位置。接著它會分析我們手的形狀和動作，像是手是張開還是握拳、是往哪個方向揮動。這些細節就像是提示，讓電腦知道我們想表達的是什麼意思。

當電腦辨識出這個手勢之後，就會把它轉換成一個具體的控制指令，例如「讓無人機起飛」、「向左移動」或「停止動作」。這些指令會即時傳送給無人機，讓它照著我們的手勢來行動。

整個過程發生得非常快，幾乎沒有延遲，讓使用者感覺就像是用手勢在「指揮」一個會飛的機器朋友，非常直覺而且有趣。

QA2.假設 DronePaint 要擴充成大型戶外表演，你認為在哪些方面需做出技術升級或安全強化？

技術升級：
訊號要更穩
戶外干擾很多，風啊、其他裝置的訊號啊，可能會影響無人機接收手勢或控制訊號，所以要讓系統抗干擾能力變強。

多台無人機要一起動得很順
如果是表演，可能會有幾十台無人機同時飛，這時候就需要一套能「統一調度」的系統，讓每一台都按照節奏一起動，不撞機、不亂飛。

定位要更準
戶外用 GPS 定位可能會有誤差，建議升級成更精準的系統，像是 RTK 定位，讓每台無人機站的位置都剛剛好。

鏡頭要適應不同光線
戶外光線變化大（白天、黃昏、晚上都有可能），手勢辨識的系統也要能在不同光線下都看得清楚，可以加裝紅外線或深度感測器來幫忙。


 安全強化：
會自動閃人、閃障礙物
無人機飛一飛如果前面有東西，它要能自己避開，或者立刻停下來，不然會撞人或東西。

失控也不怕
如果無人機突然收不到訊號，它要能自己回家，或自動找個安全的地方降落，不會亂飛一通。

觀眾跟飛行區要分開
表演現場要有明確的區域劃分，不能讓觀眾太靠近無人機，避免發生意外。

看天吃飯，也要看天飛
要加裝氣象感測器，下雨或風太大就自動暫停或取消演出，安全第一。

QA3.與鍵盤滑鼠或手機觸控相比，你認為手勢控制有何優勢？是否有明確的限制與場景？

手勢控制 vs 傳統操作方式（鍵盤、滑鼠、觸控）
✅ 手勢控制的優勢：
超直覺，不用學就會用
像揮手、比個方向，這些都是我們平常就會做的動作，幾乎不用教學，手一揮、機器就動，比打指令還快。

不用碰東西，遠端就能操控
特別適合不能接觸設備的場景，比如手髒了、戴手套，或是在展示、表演的時候，用手勢看起來也更自然、流暢。

互動感強，更有臨場感
特別在像 DronePaint 這種結合藝術或科技的表演中，手勢控制可以讓整體體驗更有「人與科技對話」的感覺。

⚠️ 但也有一些限制和挑戰：
需要好光線跟空間
如果環境太暗、太亮、或太亂，鏡頭可能看不清楚手勢，就容易失誤。

辨識速度和準確度有限
有時候手勢太快或角度奇怪，系統可能會辨識錯誤，比起滑鼠點一下，還是稍微慢一點。

不適合複雜操作
如果是像剪影片、寫報告這種需要精準控制的工作，手勢操作就不夠靈活，還是鍵盤滑鼠比較實用。

🎯 適合的應用場景：
展覽、互動裝置、舞台表演

無人機、機器人控制

醫療或工業現場（手不能碰裝置時）

智慧家庭（像比個手勢就開燈）

QA4.如果你是藝術創作者，如何利用 DronePaint 的光繪效果來傳達特定社會議題？請設計一個主題與創作構想。

創作主題：《兩個世界》
📌 議題關注：貧富差距與社會不平等
💡 創作構想：
表演以夜空為畫布，由無人機繪出一個「城市天際線」，分為左右兩邊。

畫面左邊：明亮的高樓大廈、摩天輪、煙火、閃爍的燈光，象徵繁華富裕的城市生活。

畫面右邊：建築輪廓低矮、光線微弱，有破損的房屋、搖晃的吊燈，甚至畫出飄著風的帳篷，象徵貧困邊緣的社區。

接著，無人機以燈光「畫出」兩個人物剪影——
一邊是穿著西裝、舉杯歡笑的人，另一邊是拖著空袋、看著城市的影子。

最後畫面中間升起一道光牆，看似隔開兩邊，實際上卻慢慢「裂開」，象徵兩個世界的對立也帶來社會的脆弱與不穩定。

🧠 表達重點：
用光繪對比「富」與「貧」的生活場景，讓觀眾一眼看出反差

動態變化（像是天際線逐漸傾斜、裂縫產生）來強調不平等帶來的社會張力

沒有台詞，只用畫面與音效（如鐘聲、冷風、笑聲與沉默）製造情緒落差

📍展出建議：
城市廣場或社區公共空間演出，讓議題「回到真實發生的場景」

搭配 NGO 或社福團體的行動，讓觀眾能現場掃碼了解、捐款或參與志工行動

展演結束後將空中畫面製成影片，作為教育素材或公益宣傳片使用

QA5.請列出 DronePaint 至少 3 個技術組件（如 DNN、影像偵測模組等）及它們各自的角色，並說明這些模組若缺失，系統會如何受影響？


DronePaint 的關鍵技術組件與角色：
1️⃣ 影像偵測模組（Image Detection Module）
📌 角色：
透過攝影機即時捕捉畫面，辨識使用者的手部位置、動作範圍，提供後續手勢辨識用的基礎資料。

🚫 如果缺失會怎樣？
無法辨認手在哪裡 → 系統看不到手，自然也沒辦法開始進行任何手勢辨識或操作，基本互動會失效。

2️⃣ 手勢辨識模型（通常為 DNN / 深度神經網路）
📌 角色：
分析影像中的手勢動作，判斷使用者做的是哪一種手勢（例如：揮手、舉手、比方向），並將其轉換為控制指令。

🚫 如果缺失會怎樣？
系統會看得到手，但不知道你在做什麼 → 沒辦法正確解讀動作內容，會造成誤判或完全沒反應。

3️⃣ 無人機控制模組（Drone Control Interface）
📌 角色：
負責接收手勢辨識後的指令，並轉換成無人機可以理解的語言（像是飛行路徑、燈光變化），讓無人機實際執行動作。

🚫 如果缺失會怎樣？
即使成功辨識手勢，也沒辦法把指令傳給無人機 → 使用者「比動作比得很努力」，但無人機完全沒反應或亂飛。


